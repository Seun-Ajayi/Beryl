{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/seun-ajayi/Project_4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json','r') as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "input_folder_path = config['input_folder_path']\n",
    "output_folder_path = config['output_folder_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/seun-ajayi/Project_4/practicedata'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = os.getcwd()+\"/\"+input_folder_path\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset2.csv', 'dataset1.csv', 'Icon_']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = os.listdir(os.getcwd()+\"/\"+input_folder_path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m glob(\u001b[39m\"\u001b[39;49m\u001b[39mda*\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "glob(\"da*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m filenames:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39;49m(filename)\u001b[39m.\u001b[39;49mcontains(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mprint\u001b[39m(filename)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    if str(filename).contains(\".csv\"):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(f\"{filenames}*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app.py',\n",
       " 'check.ipynb',\n",
       " 'apicalls.py',\n",
       " 'sourcedata',\n",
       " 'config.json',\n",
       " '__MACOSX',\n",
       " 'diagnostics.py',\n",
       " 'scoring.py',\n",
       " 'deployment.py',\n",
       " 'testdata',\n",
       " 'training.py']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/seun-ajayi/Project_4/practicedata/dataset1.csv\n",
      "/home/seun-ajayi/Project_4/practicedata/dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in sorted(glob(f'{input_folder_path}/*.csv')):\n",
    "       print(os.getcwd()+\"/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = os.makedirs(output_folder_path, exist_ok=True)\n",
    "OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/seun-ajayi/Project_4/practicedata/dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(os.getcwd(), output_folder_path)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{OUTPUT_DIR}/merged_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json','r') as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "dataset_csv_path = os.path.join(config['output_folder_path']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = os.listdir(os.getcwd()+\"/\"+dataset_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merged_dataset.csv'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(os.getcwd()+\"/\"+dataset_csv_path+\"/\"+data_filename[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nciw</td>\n",
       "      <td>100</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsid</td>\n",
       "      <td>68</td>\n",
       "      <td>282</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pwls</td>\n",
       "      <td>71</td>\n",
       "      <td>949</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bqlx</td>\n",
       "      <td>686</td>\n",
       "      <td>3782</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmei</td>\n",
       "      <td>45</td>\n",
       "      <td>655</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corporation  lastmonth_activity  lastyear_activity  number_of_employees  \\\n",
       "0        nciw                 100               1359                    1   \n",
       "1        lsid                  68                282                   14   \n",
       "2        pwls                  71                949                   40   \n",
       "3        bqlx                 686               3782                  103   \n",
       "4        zmei                  45                655                    7   \n",
       "\n",
       "   exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"exited\"]\n",
    "X = data.drop(columns=[\"exited\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     0\n",
       "5     1\n",
       "6     1\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    0\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    0\n",
       "17    1\n",
       "18    0\n",
       "19    0\n",
       "20    1\n",
       "21    1\n",
       "22    0\n",
       "23    1\n",
       "24    1\n",
       "25    0\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['nciw'],\n",
       "       ['lsid'],\n",
       "       ['pwls'],\n",
       "       ['bqlx'],\n",
       "       ['zmei'],\n",
       "       ['wosl'],\n",
       "       ['xcvb'],\n",
       "       ['dfgh'],\n",
       "       ['ngrd'],\n",
       "       ['xful'],\n",
       "       ['kshe'],\n",
       "       ['qqqq'],\n",
       "       ['corp'],\n",
       "       ['ekci'],\n",
       "       ['dosk'],\n",
       "       ['endi'],\n",
       "       ['gudj'],\n",
       "       ['abcd'],\n",
       "       ['asdf'],\n",
       "       ['xyzz'],\n",
       "       ['acme'],\n",
       "       ['qwer'],\n",
       "       ['tyui'],\n",
       "       ['zxcv'],\n",
       "       ['hjkl'],\n",
       "       ['lmno']], dtype=object)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = X[\"corporation\"].values\n",
    "X_cat.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= one.fit_transform(X_cat.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_con = X.drop([\"corporation\"], axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.concatenate([X_con, X_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseCoefMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Logistic Regression (aka logit, MaxEnt) classifier.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\u001b[0m\n",
      "\u001b[0;34m    scheme if the 'multi_class' option is set to 'ovr', and uses the\u001b[0m\n",
      "\u001b[0;34m    cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\u001b[0m\n",
      "\u001b[0;34m    (Currently the 'multinomial' option is supported only by the 'lbfgs',\u001b[0m\n",
      "\u001b[0;34m    'sag', 'saga' and 'newton-cg' solvers.)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This class implements regularized logistic regression using the\u001b[0m\n",
      "\u001b[0;34m    'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\u001b[0m\n",
      "\u001b[0;34m    that regularization is applied by default**. It can handle both dense\u001b[0m\n",
      "\u001b[0;34m    and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\u001b[0m\n",
      "\u001b[0;34m    floats for optimal performance; any other input format will be converted\u001b[0m\n",
      "\u001b[0;34m    (and copied).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\u001b[0m\n",
      "\u001b[0;34m    with primal formulation, or no regularization. The 'liblinear' solver\u001b[0m\n",
      "\u001b[0;34m    supports both L1 and L2 regularization, with a dual formulation only for\u001b[0m\n",
      "\u001b[0;34m    the L2 penalty. The Elastic-Net regularization is only supported by the\u001b[0m\n",
      "\u001b[0;34m    'saga' solver.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Read more in the :ref:`User Guide <logistic_regression>`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\u001b[0m\n",
      "\u001b[0;34m        Specify the norm of the penalty:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        - `'none'`: no penalty is added;\u001b[0m\n",
      "\u001b[0;34m        - `'l2'`: add a L2 penalty term and it is the default choice;\u001b[0m\n",
      "\u001b[0;34m        - `'l1'`: add a L1 penalty term;\u001b[0m\n",
      "\u001b[0;34m        - `'elasticnet'`: both L1 and L2 penalty terms are added.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. warning::\u001b[0m\n",
      "\u001b[0;34m           Some penalties may not work with some solvers. See the parameter\u001b[0m\n",
      "\u001b[0;34m           `solver` below, to know the compatibility between the penalty and\u001b[0m\n",
      "\u001b[0;34m           solver.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
      "\u001b[0;34m           l1 penalty with SAGA solver (allowing 'multinomial' + L1)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    dual : bool, default=False\u001b[0m\n",
      "\u001b[0;34m        Dual or primal formulation. Dual formulation is only implemented for\u001b[0m\n",
      "\u001b[0;34m        l2 penalty with liblinear solver. Prefer dual=False when\u001b[0m\n",
      "\u001b[0;34m        n_samples > n_features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    tol : float, default=1e-4\u001b[0m\n",
      "\u001b[0;34m        Tolerance for stopping criteria.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    C : float, default=1.0\u001b[0m\n",
      "\u001b[0;34m        Inverse of regularization strength; must be a positive float.\u001b[0m\n",
      "\u001b[0;34m        Like in support vector machines, smaller values specify stronger\u001b[0m\n",
      "\u001b[0;34m        regularization.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    fit_intercept : bool, default=True\u001b[0m\n",
      "\u001b[0;34m        Specifies if a constant (a.k.a. bias or intercept) should be\u001b[0m\n",
      "\u001b[0;34m        added to the decision function.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    intercept_scaling : float, default=1\u001b[0m\n",
      "\u001b[0;34m        Useful only when the solver 'liblinear' is used\u001b[0m\n",
      "\u001b[0;34m        and self.fit_intercept is set to True. In this case, x becomes\u001b[0m\n",
      "\u001b[0;34m        [x, self.intercept_scaling],\u001b[0m\n",
      "\u001b[0;34m        i.e. a \"synthetic\" feature with constant value equal to\u001b[0m\n",
      "\u001b[0;34m        intercept_scaling is appended to the instance vector.\u001b[0m\n",
      "\u001b[0;34m        The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Note! the synthetic feature weight is subject to l1/l2 regularization\u001b[0m\n",
      "\u001b[0;34m        as all other features.\u001b[0m\n",
      "\u001b[0;34m        To lessen the effect of regularization on synthetic feature weight\u001b[0m\n",
      "\u001b[0;34m        (and therefore on the intercept) intercept_scaling has to be increased.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    class_weight : dict or 'balanced', default=None\u001b[0m\n",
      "\u001b[0;34m        Weights associated with classes in the form ``{class_label: weight}``.\u001b[0m\n",
      "\u001b[0;34m        If not given, all classes are supposed to have weight one.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The \"balanced\" mode uses the values of y to automatically adjust\u001b[0m\n",
      "\u001b[0;34m        weights inversely proportional to class frequencies in the input data\u001b[0m\n",
      "\u001b[0;34m        as ``n_samples / (n_classes * np.bincount(y))``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Note that these weights will be multiplied with sample_weight (passed\u001b[0m\n",
      "\u001b[0;34m        through the fit method) if sample_weight is specified.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m           *class_weight='balanced'*\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    random_state : int, RandomState instance, default=None\u001b[0m\n",
      "\u001b[0;34m        Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\u001b[0m\n",
      "\u001b[0;34m        data. See :term:`Glossary <random_state>` for details.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, \\\u001b[0m\n",
      "\u001b[0;34m            default='lbfgs'\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Algorithm to use in the optimization problem. Default is 'lbfgs'.\u001b[0m\n",
      "\u001b[0;34m        To choose a solver, you might want to consider the following aspects:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            - For small datasets, 'liblinear' is a good choice, whereas 'sag'\u001b[0m\n",
      "\u001b[0;34m              and 'saga' are faster for large ones;\u001b[0m\n",
      "\u001b[0;34m            - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\u001b[0m\n",
      "\u001b[0;34m              'lbfgs' handle multinomial loss;\u001b[0m\n",
      "\u001b[0;34m            - 'liblinear' is limited to one-versus-rest schemes.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. warning::\u001b[0m\n",
      "\u001b[0;34m           The choice of the algorithm depends on the penalty chosen:\u001b[0m\n",
      "\u001b[0;34m           Supported penalties by solver:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m           - 'newton-cg'   -   ['l2', 'none']\u001b[0m\n",
      "\u001b[0;34m           - 'lbfgs'       -   ['l2', 'none']\u001b[0m\n",
      "\u001b[0;34m           - 'liblinear'   -   ['l1', 'l2']\u001b[0m\n",
      "\u001b[0;34m           - 'sag'         -   ['l2', 'none']\u001b[0m\n",
      "\u001b[0;34m           - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. note::\u001b[0m\n",
      "\u001b[0;34m           'sag' and 'saga' fast convergence is only guaranteed on\u001b[0m\n",
      "\u001b[0;34m           features with approximately the same scale. You can\u001b[0m\n",
      "\u001b[0;34m           preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. seealso::\u001b[0m\n",
      "\u001b[0;34m           Refer to the User Guide for more information regarding\u001b[0m\n",
      "\u001b[0;34m           :class:`LogisticRegression` and more specifically the\u001b[0m\n",
      "\u001b[0;34m           :ref:`Table <Logistic_regression>`\u001b[0m\n",
      "\u001b[0;34m           summarizing solver/penalty supports.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m           Stochastic Average Gradient descent solver.\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n",
      "\u001b[0;34m           SAGA solver.\u001b[0m\n",
      "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
      "\u001b[0;34m            The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    max_iter : int, default=100\u001b[0m\n",
      "\u001b[0;34m        Maximum number of iterations taken for the solvers to converge.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\u001b[0m\n",
      "\u001b[0;34m        If the option chosen is 'ovr', then a binary problem is fit for each\u001b[0m\n",
      "\u001b[0;34m        label. For 'multinomial' the loss minimised is the multinomial loss fit\u001b[0m\n",
      "\u001b[0;34m        across the entire probability distribution, *even when the data is\u001b[0m\n",
      "\u001b[0;34m        binary*. 'multinomial' is unavailable when solver='liblinear'.\u001b[0m\n",
      "\u001b[0;34m        'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\u001b[0m\n",
      "\u001b[0;34m        and otherwise selects 'multinomial'.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.18\u001b[0m\n",
      "\u001b[0;34m           Stochastic Average Gradient descent solver for 'multinomial' case.\u001b[0m\n",
      "\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n",
      "\u001b[0;34m            Default changed from 'ovr' to 'auto' in 0.22.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    verbose : int, default=0\u001b[0m\n",
      "\u001b[0;34m        For the liblinear and lbfgs solvers set verbose to any positive\u001b[0m\n",
      "\u001b[0;34m        number for verbosity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    warm_start : bool, default=False\u001b[0m\n",
      "\u001b[0;34m        When set to True, reuse the solution of the previous call to fit as\u001b[0m\n",
      "\u001b[0;34m        initialization, otherwise, just erase the previous solution.\u001b[0m\n",
      "\u001b[0;34m        Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m           *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n",
      "\u001b[0;34m        Number of CPU cores used when parallelizing over classes if\u001b[0m\n",
      "\u001b[0;34m        multi_class='ovr'\". This parameter is ignored when the ``solver`` is\u001b[0m\n",
      "\u001b[0;34m        set to 'liblinear' regardless of whether 'multi_class' is specified or\u001b[0m\n",
      "\u001b[0;34m        not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\u001b[0m\n",
      "\u001b[0;34m        context. ``-1`` means using all processors.\u001b[0m\n",
      "\u001b[0;34m        See :term:`Glossary <n_jobs>` for more details.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    l1_ratio : float, default=None\u001b[0m\n",
      "\u001b[0;34m        The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\u001b[0m\n",
      "\u001b[0;34m        used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\u001b[0m\n",
      "\u001b[0;34m        to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\u001b[0m\n",
      "\u001b[0;34m        to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\u001b[0m\n",
      "\u001b[0;34m        combination of L1 and L2.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Attributes\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    classes_ : ndarray of shape (n_classes, )\u001b[0m\n",
      "\u001b[0;34m        A list of class labels known to the classifier.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\u001b[0m\n",
      "\u001b[0;34m        Coefficient of the features in the decision function.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        `coef_` is of shape (1, n_features) when the given problem is binary.\u001b[0m\n",
      "\u001b[0;34m        In particular, when `multi_class='multinomial'`, `coef_` corresponds\u001b[0m\n",
      "\u001b[0;34m        to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    intercept_ : ndarray of shape (1,) or (n_classes,)\u001b[0m\n",
      "\u001b[0;34m        Intercept (a.k.a. bias) added to the decision function.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        If `fit_intercept` is set to False, the intercept is set to zero.\u001b[0m\n",
      "\u001b[0;34m        `intercept_` is of shape (1,) when the given problem is binary.\u001b[0m\n",
      "\u001b[0;34m        In particular, when `multi_class='multinomial'`, `intercept_`\u001b[0m\n",
      "\u001b[0;34m        corresponds to outcome 1 (True) and `-intercept_` corresponds to\u001b[0m\n",
      "\u001b[0;34m        outcome 0 (False).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_features_in_ : int\u001b[0m\n",
      "\u001b[0;34m        Number of features seen during :term:`fit`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 0.24\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    feature_names_in_ : ndarray of shape (`n_features_in_`,)\u001b[0m\n",
      "\u001b[0;34m        Names of features seen during :term:`fit`. Defined only when `X`\u001b[0m\n",
      "\u001b[0;34m        has feature names that are all strings.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionadded:: 1.0\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    n_iter_ : ndarray of shape (n_classes,) or (1, )\u001b[0m\n",
      "\u001b[0;34m        Actual number of iterations for all classes. If binary or multinomial,\u001b[0m\n",
      "\u001b[0;34m        it returns only 1 element. For liblinear solver, only the maximum\u001b[0m\n",
      "\u001b[0;34m        number of iteration across all classes is given.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        .. versionchanged:: 0.20\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\u001b[0m\n",
      "\u001b[0;34m            ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See Also\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    SGDClassifier : Incrementally trained logistic regression (when given\u001b[0m\n",
      "\u001b[0;34m        the parameter ``loss=\"log\"``).\u001b[0m\n",
      "\u001b[0;34m    LogisticRegressionCV : Logistic regression with built-in cross validation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Notes\u001b[0m\n",
      "\u001b[0;34m    -----\u001b[0m\n",
      "\u001b[0;34m    The underlying C implementation uses a random number generator to\u001b[0m\n",
      "\u001b[0;34m    select features when fitting the model. It is thus not uncommon,\u001b[0m\n",
      "\u001b[0;34m    to have slightly different results for the same input data. If\u001b[0m\n",
      "\u001b[0;34m    that happens, try with a smaller tol parameter.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Predict output may not match that of standalone liblinear in certain\u001b[0m\n",
      "\u001b[0;34m    cases. See :ref:`differences from liblinear <liblinear_differences>`\u001b[0m\n",
      "\u001b[0;34m    in the narrative documentation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    References\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\u001b[0m\n",
      "\u001b[0;34m        Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\u001b[0m\n",
      "\u001b[0;34m        http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    LIBLINEAR -- A Library for Large Linear Classification\u001b[0m\n",
      "\u001b[0;34m        https://www.csie.ntu.edu.tw/~cjlin/liblinear/\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\u001b[0m\n",
      "\u001b[0;34m        Minimizing Finite Sums with the Stochastic Average Gradient\u001b[0m\n",
      "\u001b[0;34m        https://hal.inria.fr/hal-00860051/document\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\u001b[0m\n",
      "\u001b[0;34m            :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\u001b[0m\n",
      "\u001b[0;34m            for Non-Strongly Convex Composite Objectives\" <1407.0202>`\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\u001b[0m\n",
      "\u001b[0;34m        methods for logistic regression and maximum entropy models.\u001b[0m\n",
      "\u001b[0;34m        Machine Learning 85(1-2):41-75.\u001b[0m\n",
      "\u001b[0;34m        https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    >>> from sklearn.datasets import load_iris\u001b[0m\n",
      "\u001b[0;34m    >>> from sklearn.linear_model import LogisticRegression\u001b[0m\n",
      "\u001b[0;34m    >>> X, y = load_iris(return_X_y=True)\u001b[0m\n",
      "\u001b[0;34m    >>> clf = LogisticRegression(random_state=0).fit(X, y)\u001b[0m\n",
      "\u001b[0;34m    >>> clf.predict(X[:2, :])\u001b[0m\n",
      "\u001b[0;34m    array([0, 0])\u001b[0m\n",
      "\u001b[0;34m    >>> clf.predict_proba(X[:2, :])\u001b[0m\n",
      "\u001b[0;34m    array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\u001b[0m\n",
      "\u001b[0;34m           [9.7...e-01, 2.8...e-02, ...e-08]])\u001b[0m\n",
      "\u001b[0;34m    >>> clf.score(X, y)\u001b[0m\n",
      "\u001b[0;34m    0.97...\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Fit the model according to the given training data.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : {array-like, sparse matrix} of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Training vector, where `n_samples` is the number of samples and\u001b[0m\n",
      "\u001b[0;34m            `n_features` is the number of features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        y : array-like of shape (n_samples,)\u001b[0m\n",
      "\u001b[0;34m            Target vector relative to X.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        sample_weight : array-like of shape (n_samples,) default=None\u001b[0m\n",
      "\u001b[0;34m            Array of weights that are assigned to individual samples.\u001b[0m\n",
      "\u001b[0;34m            If not provided, then each sample is given unit weight.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m            .. versionadded:: 0.17\u001b[0m\n",
      "\u001b[0;34m               *sample_weight* support to LogisticRegression.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        self\u001b[0m\n",
      "\u001b[0;34m            Fitted estimator.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Notes\u001b[0m\n",
      "\u001b[0;34m        -----\u001b[0m\n",
      "\u001b[0;34m        The SAGA solver supports both float64 and float32 bit arrays.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Penalty term must be positive; got (C=%r)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"elasticnet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"l1_ratio must be between 0 and 1; got (l1_ratio=%r)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"l1_ratio parameter is only used when penalty is \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"'elasticnet'. Got \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"(penalty={})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"none\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# default values\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Setting penalty='none' will ignore the C and l1_ratio parameters\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Note that check for l1_ratio is done right above\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mC_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mC_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Maximum number of iteration must be positive; got (max_iter=%r)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Tolerance for stopping criteria must be positive; got (tol=%r)\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmulti_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_multi_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"'n_jobs' > 1 does not have any effect when\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\" 'solver' is set to 'liblinear'. Got 'n_jobs'\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\" = {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fit_liblinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_squared_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_squared_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"This solver needs samples of at least 2 classes\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\" class: %r\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m%\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwarm_start_coef\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Hack so that we iterate only once for the multinomial case.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multinomial\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mwarm_start_coef\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mwarm_start_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpath_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_logistic_regression_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# The SAG solver releases the GIL so it's more efficient to use\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# threads for this solver.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"threads\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"processes\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# TODO: Refactor this to avoid joblib parallelism entirely when doing binary\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# and multinomial multiclass classification and use joblib only for the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# one-vs-rest multiclass case.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msolver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# In the future, we would like n_threads = _openmp_effective_n_threads()\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# For the time being, we just do\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfold_coefs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpath_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpos_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mCs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcoef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarm_start_coef_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mn_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multinomial\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Probability estimates.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The returned estimates for all classes are ordered by the\u001b[0m\n",
      "\u001b[0;34m        label of classes.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        For a multi_class problem, if multi_class is set to be \"multinomial\"\u001b[0m\n",
      "\u001b[0;34m        the softmax function is used to find the predicted probability of\u001b[0m\n",
      "\u001b[0;34m        each class.\u001b[0m\n",
      "\u001b[0;34m        Else use a one-vs-rest approach, i.e calculate the probability\u001b[0m\n",
      "\u001b[0;34m        of each class assuming it to be positive using the logistic function.\u001b[0m\n",
      "\u001b[0;34m        and normalize these values across all the classes.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Vector to be scored, where `n_samples` is the number of samples and\u001b[0m\n",
      "\u001b[0;34m            `n_features` is the number of features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        T : array-like of shape (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Returns the probability of the sample for each class in the model,\u001b[0m\n",
      "\u001b[0;34m            where classes are ordered as they are in ``self.classes_``.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0movr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# which requires softmax prediction with only a 1D decision.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdecision_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdecision_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Predict logarithm of probability estimates.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The returned estimates for all classes are ordered by the\u001b[0m\n",
      "\u001b[0;34m        label of classes.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Parameters\u001b[0m\n",
      "\u001b[0;34m        ----------\u001b[0m\n",
      "\u001b[0;34m        X : array-like of shape (n_samples, n_features)\u001b[0m\n",
      "\u001b[0;34m            Vector to be scored, where `n_samples` is the number of samples and\u001b[0m\n",
      "\u001b[0;34m            `n_features` is the number of features.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns\u001b[0m\n",
      "\u001b[0;34m        -------\u001b[0m\n",
      "\u001b[0;34m        T : array-like of shape (n_samples, n_classes)\u001b[0m\n",
      "\u001b[0;34m            Returns the log-probability of the sample for each class in the\u001b[0m\n",
      "\u001b[0;34m            model, where classes are ordered as they are in ``self.classes_``.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/yes/envs/tourmaline/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     LogisticRegressionCV\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100.0,\n",
       "  1359.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.0,\n",
       "  282.0,\n",
       "  14.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [71.0,\n",
       "  949.0,\n",
       "  40.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [686.0,\n",
       "  3782.0,\n",
       "  103.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [45.0,\n",
       "  655.0,\n",
       "  7.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [189.0,\n",
       "  961.0,\n",
       "  18.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.0,\n",
       "  1028.0,\n",
       "  33.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [9.0,\n",
       "  45.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  67.0,\n",
       "  14.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [48.0,\n",
       "  986.0,\n",
       "  22.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [52.0,\n",
       "  650.0,\n",
       "  11.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [1090.0,\n",
       "  2452.0,\n",
       "  9.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [6.0,\n",
       "  88.0,\n",
       "  90.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [99.0,\n",
       "  390.0,\n",
       "  99.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [75.0,\n",
       "  800.0,\n",
       "  81.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [255.0,\n",
       "  1687.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [78.0,\n",
       "  1024.0,\n",
       "  12.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [14.0,\n",
       "  2145.0,\n",
       "  20.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [182.0,\n",
       "  3891.0,\n",
       "  35.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [101.0,\n",
       "  10983.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  118.0,\n",
       "  42.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [929.0,\n",
       "  1992.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [19.0,\n",
       "  455.0,\n",
       "  8.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [94.0,\n",
       "  868.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [81.0,\n",
       "  1401.0,\n",
       "  10.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100.0,\n",
       "  1359.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.0,\n",
       "  282.0,\n",
       "  14.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [71.0,\n",
       "  949.0,\n",
       "  40.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [686.0,\n",
       "  3782.0,\n",
       "  103.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [45.0,\n",
       "  655.0,\n",
       "  7.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [189.0,\n",
       "  961.0,\n",
       "  18.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.0,\n",
       "  1028.0,\n",
       "  33.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [9.0,\n",
       "  45.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  67.0,\n",
       "  14.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [48.0,\n",
       "  986.0,\n",
       "  22.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [52.0,\n",
       "  650.0,\n",
       "  11.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [1090.0,\n",
       "  2452.0,\n",
       "  9.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [6.0,\n",
       "  88.0,\n",
       "  90.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [99.0,\n",
       "  390.0,\n",
       "  99.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [75.0,\n",
       "  800.0,\n",
       "  81.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [255.0,\n",
       "  1687.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [78.0,\n",
       "  1024.0,\n",
       "  12.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [14.0,\n",
       "  2145.0,\n",
       "  20.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [182.0,\n",
       "  3891.0,\n",
       "  35.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [101.0,\n",
       "  10983.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  118.0,\n",
       "  42.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [929.0,\n",
       "  1992.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [19.0,\n",
       "  455.0,\n",
       "  8.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [94.0,\n",
       "  868.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [81.0,\n",
       "  1401.0,\n",
       "  10.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(X_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_json = json.dumps(X_final.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[100.0, 1359.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [68.0, 282.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [71.0, 949.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [686.0, 3782.0, 103.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [45.0, 655.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 18.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [189.0, 961.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [16.0, 1028.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.0, 45.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 67.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [48.0, 986.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [52.0, 650.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1090.0, 2452.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.0, 88.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [99.0, 390.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [75.0, 800.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [255.0, 1687.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [78.0, 1024.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [14.0, 2145.0, 20.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [182.0, 3891.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [101.0, 10983.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 118.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [929.0, 1992.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [19.0, 455.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [94.0, 868.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [81.0, 1401.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                    multi_class='multinomial', n_jobs=None, penalty='l2',\n",
    "                    random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                    warm_start=False)\n",
    "    \n",
    "#fit the logistic regression to your data\n",
    "model = lr.fit(X_final, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import preprocess_data\n",
    "from scoring import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = load_model(modelfile=\"encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1, *_ = preprocess_data(datapath=dataset_csv_path, training=False, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = [float(x) for x in list(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_json1 = json.dumps(X_test1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[100.0, 1359.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [68.0, 282.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [71.0, 949.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [686.0, 3782.0, 103.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [45.0, 655.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 18.0, 21.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [189.0, 961.0, 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [16.0, 1028.0, 33.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.0, 45.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 67.0, 14.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [48.0, 986.0, 22.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [52.0, 650.0, 11.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1090.0, 2452.0, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.0, 88.0, 90.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [99.0, 390.0, 99.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [75.0, 800.0, 81.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [255.0, 1687.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [78.0, 1024.0, 12.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [14.0, 2145.0, 20.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [182.0, 3891.0, 35.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [101.0, 10983.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 118.0, 42.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [929.0, 1992.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [19.0, 455.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [94.0, 868.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [81.0, 1401.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_json1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#Y306sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_json[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "X_json['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(json.loads(X_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1359.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>686.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>189.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1090.0</td>\n",
       "      <td>2452.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>75.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>255.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>182.0</td>\n",
       "      <td>3891.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101.0</td>\n",
       "      <td>10983.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>929.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>19.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>94.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>81.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1      2    3    4    5    6    7    8    9   ...   19   20  \\\n",
       "0    100.0   1359.0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     68.0    282.0   14.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     71.0    949.0   40.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "3    686.0   3782.0  103.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4     45.0    655.0    7.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "5      0.0     18.0   21.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "6    189.0    961.0   18.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "7     16.0   1028.0   33.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "8      9.0     45.0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "9      0.0     67.0   14.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "10    48.0    986.0   22.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "11    52.0    650.0   11.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n",
       "12  1090.0   2452.0    9.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "13     6.0     88.0   90.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "14    99.0    390.0   99.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0   \n",
       "15    75.0    800.0   81.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "16   255.0   1687.0    2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "17    78.0   1024.0   12.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "18    14.0   2145.0   20.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "19   182.0   3891.0   35.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "20   101.0  10983.0    2.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "21     0.0    118.0   42.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "22   929.0   1992.0    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "23    19.0    455.0    8.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "24    94.0    868.0    3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "25    81.0   1401.0   10.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "     21   22   23   24   25   26   27   28  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "5   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "21  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "24  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[26 rows x 29 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(json.loads(X_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = lr.fit(check1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = log.predict(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.score(X_final,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = \"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde = \"cde\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc/cde'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = abc+\"/\"+cde\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = glob(f\"{os.path.join(os.getcwd(), dataset_csv_path)}/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/seun-ajayi/Project_4/ingesteddata/merged_dataset.csv']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json','r') as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "model_scores_path = os.path.join(config['model_scores_path']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"metric\", \"version\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrow = {\"metric\": \"f1\", \"version\": 0, \"score\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1125/4285175607.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(newrow, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = df.append(newrow, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>version</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric version score\n",
       "0     f1       0     0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{model_scores_path}/modelscores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(os.getcwd(), model_scores_path, \"modelscores.csv\")\n",
    "previousscores = pd.read_csv(filepath)\n",
    "maxversion=previousscores['version'].max()\n",
    "thisversion=maxversion+1\n",
    "new_row_f1 = {'metric':'f1score', 'version':thisversion, 'score':f1score}\n",
    "if f1score<previousscores.loc[previousscores['metric']=='f1score','score'].min():\n",
    "    previousscores = previousscores.append(new_row_f1, ignore_index=True)\n",
    "    # previousscores.head()\n",
    "    previousscores.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>version</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric  version   score\n",
       "0     f1        1  0.9375"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousscores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previousscores.loc[previousscores['metric']=='f1', \"score\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "copy() missing 2 required positional arguments: 'src' and 'dst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m shutil\u001b[39m.\u001b[39;49mcopy()\n",
      "\u001b[0;31mTypeError\u001b[0m: copy() missing 2 required positional arguments: 'src' and 'dst'"
     ]
    }
   ],
   "source": [
    "shutil.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'check_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 63\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#Y121sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m outdated \u001b[39m=\u001b[39m  subprocess\u001b[39m.\u001b[39;49mcheck_output([\u001b[39m\"\u001b[39;49m\u001b[39mpip\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlist\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--outdated\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39;49mcheck_output([\u001b[39m\"\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m--outdated\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'check_output'"
     ]
    }
   ],
   "source": [
    "outdated =  subprocess.check_output([\"pip\", \"list\", \"--outdated\"]).check_output([\"pip\", \"list\", \"--outdated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  2],\n",
       "       [ 0, 15]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsgElEQVR4nO3de3RU9bn/8c8kIZMEkpCoJEQCxKIIikFBOYgKnKYitQh1ebwUNVKllZsCgsCy4SrES0VEKShWkP6k4qnCUax4KMqtohYwVCtEAgEidw9CSDC3mf37A5k6hstM9p7M7Nnv11p7rc6efXmmK8uH5/l+9/66DMMwBAAAbCkm3AEAAICGI5EDAGBjJHIAAGyMRA4AgI2RyAEAsDESOQAANkYiBwDAxuLCHYAZXq9X+/btU3JyslwuV7jDAQAEyTAMHT9+XFlZWYqJCV1tWVVVpZqaGtPXiY+PV0JCggURWcfWiXzfvn3Kzs4OdxgAAJPKysrUqlWrkFy7qqpKOW2a6cAhj+lrZWZmqrS0NKKSua0TeXJysiSp9QtjFZPoDnM0QGhc9Gx1uEMAQqbOU621W2f7/nseCjU1NTpwyKPdm9oqJbnhVX/5ca/adNmlmpoaErlVTrXTYxLdikmKnP9TASvFxYY7AiD0GmN4tFmyS82SG34fryJzCNfWiRwAgEB5DK88JlYX8Rhe64KxEIkcAOAIXhnyquGZ3My5ocTjZwAA2BgVOQDAEbzyykxz3NzZoUMiBwA4gscw5DEa3h43c24o0VoHAMDGqMgBAI4QrZPdSOQAAEfwypAnChM5rXUAAGyMihwA4Ai01gEAsDFmrQMAgIhDRQ4AcATv95uZ8yMRiRwA4Agek7PWzZwbSiRyAIAjeAyZXP3MulisxBg5AAA2RkUOAHAExsgBALAxr1zyyGXq/EhEax0AgBBYu3at+vXrp6ysLLlcLi1btuyMxz744INyuVyaNWtW0PchkQMAHMFrmN+CUVlZqdzcXM2ZM+esxy1dulQff/yxsrKyGvS7aK0DABzBY7K1Huy5ffv2Vd++fc96zN69ezVixAi9//77uvnmmxsUF4kcAIAglJeX+312u91yu91BX8fr9eqee+7R2LFjddlllzU4HlrrAABHOFWRm9kkKTs7W6mpqb6tsLCwQfE8+eSTiouL00MPPWTqd1GRAwAcwWu45DVMzFr//tyysjKlpKT49jekGt+0aZOee+45bd68WS6XudnwVOQAAAQhJSXFb2tIIl+3bp0OHTqk1q1bKy4uTnFxcdq9e7ceeeQRtW3bNqhrUZEDAByhsSe7nc0999yjvLw8v319+vTRPffco0GDBgV1LRI5AMARPIqRx0Qj2hPk8RUVFSopKfF9Li0tVVFRkdLT09W6dWudd955fsc3adJEmZmZat++fVD3IZEDABzBMDlGbgR57saNG9W7d2/f59GjR0uS8vPztXDhwgbH8WMkcgAAQqBXr14yjMDfIrNr164G3YdEDgBwhEgaI7cSiRwA4AgeI0Yew8QYOeuRAwAAq1GRAwAcwSuXvCbqV68isyQnkQMAHCFax8hprQMAYGNU5AAARzA/2Y3WOgAAYXNyjNzEoim01gEAgNWoyAEAjuA1+a51Zq0DABBGjJEDAGBjXsVE5XPkjJEDAGBjVOQAAEfwGC55TCxjaubcUCKRAwAcwWNyspuH1joAALAaFTkAwBG8Roy8Jmate5m1DgBA+NBaBwAAEYeKHADgCF6Zm3nutS4US5HIAQCOYP6FMJHZxI7MqAAAQECoyAEAjmD+XeuRWfuSyAEAjhCt65GTyAEAjhCtFXlkRgUAAAJCRQ4AcATzL4SJzNqXRA4AcASv4ZLXzHPkEbr6WWT+8wIAAASEihwA4Ahek631SH0hDIkcAOAI5lc/i8xEHplRAQCAgFCRAwAcwSOXPCZe6mLm3FAikQMAHIHWOgAAiDhU5AAAR/DIXHvcY10oliKRAwAcIVpb6yRyAIAjsGgKAAAI2Nq1a9WvXz9lZWXJ5XJp2bJlvu9qa2s1btw4derUSU2bNlVWVpbuvfde7du3L+j7kMgBAI5gfL8eeUM3I8jx9crKSuXm5mrOnDn1vjtx4oQ2b96sgoICbd68WW+99ZaKi4t1yy23BP27aK0DAByhsVvrffv2Vd++fU/7XWpqqlauXOm374UXXtA111yjPXv2qHXr1gHfh0QOAEAQysvL/T673W653W7T1z127JhcLpeaN28e1Hm01gEAjnBqGVMzmyRlZ2crNTXVtxUWFpqOraqqSuPGjdNdd92llJSUoM6lIgcAOILH5Opnp84tKyvzS7Zmq/Ha2lrdfvvtMgxDc+fODfp8EjkAAEFISUkJumo+k1NJfPfu3frggw8adF0SOQDAEX7YHm/o+VY6lcS3b9+uDz/8UOedd16DrkMiBwA4glcx8pporQd7bkVFhUpKSnyfS0tLVVRUpPT0dLVs2VK33XabNm/erOXLl8vj8ejAgQOSpPT0dMXHxwd8HxI5AAAhsHHjRvXu3dv3efTo0ZKk/Px8TZ48WW+//bYkqXPnzn7nffjhh+rVq1fA9yGRAwAcwWO45DHRHg/23F69eskwjDN+f7bvgkEiBwA4QqSNkVuFRA4AcATD5OpnBoumAAAAq1GRAwAcwSOXPEEufPLj8yMRiRwA4Ahew9w4t9eauWmWo7UOAICNUZEjIK7vPEr/7/1K2nhMscfqVNM2Uf93bytV/yQp3KEBpt1+x5fq0eNrtWp1XDU1sfryy/P1yitXaO/X1ryGE5HBa3Kym5lzQ4lEjoBcML9M8WVVOjykjerSmih5/RG1nFGisqcvlSc98DcQAZGoU6fDeuedi/XVV+mKjfHqvkGfa/r0Nfrtb/qqupr/TEYLr1zymhjnNnNuKEXEPy/mzJmjtm3bKiEhQd26ddOnn34a7pDwA64ar5p+elT/96uWqurQTHWZbn17W0vVZriV8rf/C3d4gGkFv+upv63M0Z7dqSotTdPMZ65RRsYJXXzxkXCHBpxT2BP5kiVLNHr0aE2aNEmbN29Wbm6u+vTpo0OHDoU7NJziMeTySkYT/z8XIz5GCcUVYQoKCJ2kpFpJ0vHjdJuiyak3u5nZIlHYE/nMmTM1ePBgDRo0SB07dtS8efOUlJSkV155Jdyh4XtGYqyqLk5S2tIDiv22VvIaarb+iNzbKxV7tC7c4QGWcrkM/fbBz/Svf52v3bubhzscWOjUGLmZLRKFNaqamhpt2rRJeXl5vn0xMTHKy8vThg0b6h1fXV2t8vJyvw2N49DQNpIhtRn2L+Xcu0UpK75RxbVpitAhI6DBhg3bpLZtj+mJwu7hDgUISFhncXzzzTfyeDzKyMjw25+RkaFt27bVO76wsFBTpkxprPDwA3UZbu2feLFcVR7FfOeVJ62JWszepboW7nCHBlhmyNBNuqbbPo0d85/65hueyIg2Xpl813qEVi6R2Sc4gwkTJujYsWO+raysLNwhOY6RECtPWhPFVNQp8Z/lquzC4zmIBoaGDN2ka6/dq/HjeuvgwWbhDgghYHw/a72hmxGhiTysFfn555+v2NhYHTx40G//wYMHlZmZWe94t9stt5sKMBwSt5wcxqht6VaTgzVKX7xXtVkJOt7zvDBHBpg3bNgm9eq9R1OnXKfvvotTWtp3kqTKyiaqqeHxs2jB6mchEB8fry5dumjVqlUaMGCAJMnr9WrVqlUaPnx4OEPDj8R851H66/sVd6RWnmaxqry6uY7c0VKKi8w/bCAYv+i3Q5L01NMf+u1/5plr9LeVOeEICQhY2P+pOXr0aOXn56tr16665pprNGvWLFVWVmrQoEHhDg0/UPkfaar8j7RwhwGERN+b7gh3CGgEvNktRO644w4dPnxYEydO1IEDB9S5c2etWLGi3gQ4AADMoLUeQsOHD6eVDgBAA0REIgcAINSi9V3rJHIAgCNEa2s9MkfuAQBAQKjIAQCOEK0VOYkcAOAI0ZrIaa0DAGBjVOQAAEeI1oqcRA4AcARD5h4hM6wLxVIkcgCAI0RrRc4YOQAANkZFDgBwhGityEnkAABHiNZETmsdAAAboyIHADhCtFbkJHIAgCMYhkuGiWRs5txQorUOAICNUZEDAByB9cgBALCxaB0jp7UOAICNUZEDAByByW4AANjYqda6mS0Ya9euVb9+/ZSVlSWXy6Vly5b5fW8YhiZOnKiWLVsqMTFReXl52r59e9C/i0QOAHCEUxW5mS0YlZWVys3N1Zw5c077/VNPPaXZs2dr3rx5+uSTT9S0aVP16dNHVVVVQd2H1joAAEEoLy/3++x2u+V2u+sd17dvX/Xt2/e01zAMQ7NmzdLvfvc79e/fX5K0aNEiZWRkaNmyZbrzzjsDjoeKHADgCIbJtvqpijw7O1upqam+rbCwMOhYSktLdeDAAeXl5fn2paamqlu3btqwYUNQ16IiBwA4giHJMMydL0llZWVKSUnx7T9dNX4uBw4ckCRlZGT47c/IyPB9FygSOQAAQUhJSfFL5OFGax0A4Ain3uxmZrNKZmamJOngwYN++w8ePOj7LlAkcgCAIzT2rPWzycnJUWZmplatWuXbV15erk8++UTdu3cP6lq01gEACIGKigqVlJT4PpeWlqqoqEjp6elq3bq1Ro4cqccff1wXX3yxcnJyVFBQoKysLA0YMCCo+5DIAQCO4DVccjXiu9Y3btyo3r17+z6PHj1akpSfn6+FCxfq0UcfVWVlpX7zm9/o6NGjuu6667RixQolJCQEdR8SOQDAEQzD5Kz1IM/t1auXjLOc5HK5NHXqVE2dOrXhQYkxcgAAbI2KHADgCNG6aAqJHADgCCRyAABsrLEnuzUWxsgBALAxKnIAgCM09qz1xkIiBwA4wslEbmaM3MJgLERrHQAAG6MiBwA4ArPWAQCwMUP/XlO8oedHIlrrAADYGBU5AMARaK0DAGBnUdpbJ5EDAJzBZEWuCK3IGSMHAMDGqMgBAI7Am90AALCxaJ3sRmsdAAAboyIHADiD4TI3YS1CK3ISOQDAEaJ1jJzWOgAANkZFDgBwBl4IAwCAfUXrrPWAEvnbb78d8AVvueWWBgcDAACCE1AiHzBgQEAXc7lc8ng8ZuIBACB0IrQ9bkZAidzr9YY6DgAAQipaW+umZq1XVVVZFQcAAKFlWLBFoKATucfj0bRp03ThhReqWbNm2rlzpySpoKBAf/zjHy0PEAAAnFnQiXz69OlauHChnnrqKcXHx/v2X3755Xr55ZctDQ4AAOu4LNgiT9CJfNGiRXrppZc0cOBAxcbG+vbn5uZq27ZtlgYHAIBlaK2ftHfvXrVr167efq/Xq9raWkuCAgAAgQk6kXfs2FHr1q2rt/8vf/mLrrzySkuCAgDAclFakQf9ZreJEycqPz9fe/fuldfr1VtvvaXi4mItWrRIy5cvD0WMAACYF6WrnwVdkffv31/vvPOO/va3v6lp06aaOHGitm7dqnfeeUc/+9nPQhEjAAA4gwa9a/3666/XypUrrY4FAICQidZlTBu8aMrGjRu1detWSSfHzbt06WJZUAAAWI7Vz076+uuvddddd+nvf/+7mjdvLkk6evSorr32Wr3++utq1aqV1TECAIAzCHqM/IEHHlBtba22bt2qI0eO6MiRI9q6dau8Xq8eeOCBUMQIAIB5pya7mdkiUNCJfM2aNZo7d67at2/v29e+fXs9//zzWrt2raXBAQBgFZdhfguGx+NRQUGBcnJylJiYqJ/85CeaNm2aDIsH24NurWdnZ5/2xS8ej0dZWVmWBAUAgOUaeYz8ySef1Ny5c/Xqq6/qsssu08aNGzVo0CClpqbqoYceMhGIv6Ar8qefflojRozQxo0bffs2btyohx9+WL///e8tCwwAADv76KOP1L9/f918881q27atbrvtNt1444369NNPLb1PQBV5WlqaXK5/jw1UVlaqW7duios7eXpdXZ3i4uL061//WgMGDLA0QAAALGHRC2HKy8v9drvdbrnd7nqHX3vttXrppZf01Vdf6ZJLLtGWLVu0fv16zZw5s+ExnEZAiXzWrFmW3hQAgEZnUWs9Ozvbb/ekSZM0efLkeoePHz9e5eXluvTSSxUbGyuPx6Pp06dr4MCBJoKoL6BEnp+fb+lNAQCwq7KyMqWkpPg+n64al6Q33nhDr732mhYvXqzLLrtMRUVFGjlypLKysizNqw1+IYwkVVVVqaamxm/fD38cAAARw6KKPCUlJaBcN3bsWI0fP1533nmnJKlTp07avXu3CgsLLU3kQU92q6ys1PDhw9WiRQs1bdpUaWlpfhsAABGpkVc/O3HihGJi/NNsbGysvF6viR9RX9CJ/NFHH9UHH3yguXPnyu126+WXX9aUKVOUlZWlRYsWWRocAAB21a9fP02fPl3vvvuudu3apaVLl2rmzJn65S9/ael9gm6tv/POO1q0aJF69eqlQYMG6frrr1e7du3Upk0bvfbaa5YP4gMAYIlGXsb0+eefV0FBgYYOHapDhw4pKytLv/3tbzVx4sSGx3AaQSfyI0eO6KKLLpJ0cpzgyJEjkqTrrrtOQ4YMsTQ4AACs0pC3s/34/GAkJydr1qxZIX/yK+jW+kUXXaTS0lJJ0qWXXqo33nhD0slK/dQiKgAAoHEEncgHDRqkLVu2SDr5jNycOXOUkJCgUaNGaezYsZYHCACAJRp5sltjCbq1PmrUKN//zsvL07Zt27Rp0ya1a9dOV1xxhaXBAQCAszP1HLkktWnTRm3atLEiFgAAQsYlk2PklkVirYAS+ezZswO+oJUrugAAgLMLKJE/++yzAV3M5XKFJZG3vf9zxbmaNPp9gcbw3r6icIcAhEz5ca/SLmmkmzXy42eNJaBEfmqWOgAAttXI65E3lqBnrQMAgMhherIbAAC2EKUVOYkcAOAIjf1mt8ZCax0AABujIgcAOEOUttYbVJGvW7dOd999t7p37669e/dKkv70pz9p/fr1lgYHAIBlovQVrUEn8jfffFN9+vRRYmKiPvvsM1VXV0uSjh07phkzZlgeIAAAOLOgE/njjz+uefPmaf78+WrS5N8vYenRo4c2b95saXAAAFjl1GQ3M1skCnqMvLi4WDfccEO9/ampqTp69KgVMQEAYL0ofbNb0BV5ZmamSkpK6u1fv369LrroIkuCAgDAcoyRnzR48GA9/PDD+uSTT+RyubRv3z699tprGjNmjIYMGRKKGAEAwBkE3VofP368vF6vfvrTn+rEiRO64YYb5Ha7NWbMGI0YMSIUMQIAYFq0vhAm6ETucrn02GOPaezYsSopKVFFRYU6duyoZs2ahSI+AACsEaXPkTf4hTDx8fHq2LGjlbEAAIAgBZ3Ie/fuLZfrzDP3PvjgA1MBAQAQEmYfIYuWirxz585+n2tra1VUVKQvvvhC+fn5VsUFAIC1aK2f9Oyzz552/+TJk1VRUWE6IAAAEDjLVj+7++679corr1h1OQAArBWlz5FbtvrZhg0blJCQYNXlAACwFI+ffe/WW2/1+2wYhvbv36+NGzeqoKDAssAAAMC5BZ3IU1NT/T7HxMSoffv2mjp1qm688UbLAgMAAOcWVCL3eDwaNGiQOnXqpLS0tFDFBACA9aJ01npQk91iY2N14403ssoZAMB2onUZ06BnrV9++eXauXNnKGIBAABBCjqRP/744xozZoyWL1+u/fv3q7y83G8DACBiRdmjZ1IQY+RTp07VI488op///OeSpFtuucXvVa2GYcjlcsnj8VgfJQAAZkXpGHnAiXzKlCl68MEH9eGHH4YyHgAAEISAE7lhnPynSM+ePUMWDAAAocILYaSzrnoGAEBEc3prXZIuueSScybzI0eOmAoIAAAELqhEPmXKlHpvdgMAwA5orUu688471aJFi1DFAgBA6IShtb53716NGzdO7733nk6cOKF27dppwYIF6tq1q4lA/AWcyBkfBwAgcN9++6169Oih3r1767333tMFF1yg7du3W/6K86BnrQMAYEuNXJE/+eSTys7O1oIFC3z7cnJyTARwegG/2c3r9dJWBwDYllXvWv/xG02rq6tPe7+3335bXbt21X/913+pRYsWuvLKKzV//nzLf1fQr2gFAMCWzLye9QfVfHZ2tlJTU31bYWHhaW+3c+dOzZ07VxdffLHef/99DRkyRA899JBeffVVS39W0OuRAwDgZGVlZUpJSfF9drvdpz3O6/Wqa9eumjFjhiTpyiuv1BdffKF58+YpPz/fsnioyAEAzmBRRZ6SkuK3nSmRt2zZUh07dvTb16FDB+3Zs8fSn0VFDgBwhMZ+jrxHjx4qLi722/fVV1+pTZs2DQ/iNKjIAQAIgVGjRunjjz/WjBkzVFJSosWLF+ull17SsGHDLL0PiRwA4AwWtdYDdfXVV2vp0qX685//rMsvv1zTpk3TrFmzNHDgQGt+z/dorQMAHCEcr2j9xS9+oV/84hcNv2kAqMgBALAxKnIAgDOwjCkAADYWpYmc1joAADZGRQ4AcATX95uZ8yMRiRwA4AxR2lonkQMAHCEcj581BsbIAQCwMSpyAIAz0FoHAMDmIjQZm0FrHQAAG6MiBwA4QrROdiORAwCcIUrHyGmtAwBgY1TkAABHoLUOAICd0VoHAACRhoocAOAItNYBALCzKG2tk8gBAM4QpYmcMXIAAGyMihwA4AiMkQMAYGe01gEAQKShIgcAOILLMOQyGl5Wmzk3lEjkAABnoLUOAAAiDRU5AMARmLUOAICd0VoHAACRhoocAOAItNYBALCzKG2tk8gBAI4QrRU5Y+QAANgYFTkAwBlorQMAYG+R2h43g9Y6AAA2RkUOAHAGwzi5mTk/ApHIAQCOwKx1AADQIE888YRcLpdGjhxp+bWpyAEAzhCmWev/+Mc/9OKLL+qKK64wcfMzoyIHADiCy2t+k6Ty8nK/rbq6+oz3rKio0MCBAzV//nylpaWF5HeRyAEACEJ2drZSU1N9W2Fh4RmPHTZsmG6++Wbl5eWFLB5a6whYv/u+0W1DDin9gjrt/DJRf/jdhSouSgp3WEDQPv+4qf77Dy20/fMkHTnYRJP+WKpr+x7zff/7ka218o10v3O69CrXjMU7GztUWMmi1npZWZlSUlJ8u91u92kPf/3117V582b94x//MHHTcyORIyA9b/lWv5m0T8+Pb6Vtm5P0y8GHNX3xTt1/fXsd+78m4Q4PCErViRhddNl36nPXEU29P+e0x3TtXa5Hnt3j+9wkPkKnLCNgVs1aT0lJ8Uvkp1NWVqaHH35YK1euVEJCQsNvGoCwttbXrl2rfv36KSsrSy6XS8uWLQtnODiLW3/zjVYsTtf/LknXnu0Jmj2ulaq/c6nPXUfCHRoQtKv/87juG3dAPX5Qhf9Yk3hD6S3qfFtyc08jRoiQOPUcuZktQJs2bdKhQ4d01VVXKS4uTnFxcVqzZo1mz56tuLg4eTzW/T2FNZFXVlYqNzdXc+bMCWcYOIe4Jl5dfMUJbV6X7NtnGC59ti5ZHbucCGNkQOj8c0Mz3d7pMt1/3aWaPb6Vyo/Ehjsk2MhPf/pTff755yoqKvJtXbt21cCBA1VUVKTYWOv+nsLaWu/bt6/69u0b8PHV1dV+swPLy8tDERZ+JCXdo9g46ehh/z+Xb7+JU3a7M8/WBOyqa69y9eh7VJmta7R/l1sLnmipx+6+SLPe2S4L//uLRtaYL4RJTk7W5Zdf7revadOmOu+88+rtN8tWY+SFhYWaMmVKuMMAEOV6DTjq+985HaqU0/E73de9o/75UTNdeX1F+AKDOVG6+pmtHj+bMGGCjh075tvKysrCHZIjlB+JladOan5Bnd/+tPPr9O1hW/1bEGiQlm1qlJpep327Tj87GQjE6tWrNWvWLMuva6tE7na7fbMFA5k1CGvU1cZo+z+TdOV1x337XC5Dna+r0JebePwM0e/wviYq/zZW6S1qwx0KTDjVWjezRSLKKQTkrZfO15hZZfpqS5KKPzv5+FlCklf/+3r6uU8GIsx3lTHaV/rv6vpAWbx2fJGo5OZ1Sk7z6P89k6nrbj6qtBZ12r8rXi8/nqWsnGp16XX8LFdFxGP1MzjZmrfTlHqeR/eOPaC0C+q081+Jemxgjo5+wzPksJ+vtiTp0dva+T6/OPlCSdLPbj+iEYVlKt2aoJX/naPK8lidl1Gnq3qWK//RA4p3R+Z/yOFsYU3kFRUVKikp8X0uLS1VUVGR0tPT1bp16zBGhtN5e8H5envB+eEOAzAt99oKvb+v6Izfz/gzb3CLRtG6jGlYE/nGjRvVu3dv3+fRo0dLkvLz87Vw4cIwRQUAiEpROms9rIm8V69eMiJ0zAEAADtgjBwA4Ai01gEAsDOvcXIzc34EIpEDAJwhSsfIbfVCGAAA4I+KHADgCC6ZHCO3LBJrkcgBAM4QpW92o7UOAICNUZEDAByBx88AALAzZq0DAIBIQ0UOAHAEl2HIZWLCmplzQ4lEDgBwBu/3m5nzIxCtdQAAbIyKHADgCLTWAQCwsyidtU4iBwA4A292AwAAkYaKHADgCLzZDQAAO6O1DgAAIg0VOQDAEVzek5uZ8yMRiRwA4Ay01gEAQKShIgcAOAMvhAEAwL6i9RWttNYBALAxKnIAgDNE6WQ3EjkAwBkMmVtTPDLzOIkcAOAMjJEDAICIQ0UOAHAGQybHyC2LxFIkcgCAM0TpZDda6wAAhEBhYaGuvvpqJScnq0WLFhowYICKi4stvw+JHADgDF4LtiCsWbNGw4YN08cff6yVK1eqtrZWN954oyorK635Pd+jtQ4AcASrZq2Xl5f77Xe73XK73fWOX7Fihd/nhQsXqkWLFtq0aZNuuOGGBsfxY1TkAAAEITs7W6mpqb6tsLAwoPOOHTsmSUpPT7c0HipyAIAzWDTZraysTCkpKb7dp6vGf8zr9WrkyJHq0aOHLr/88obHcBokcgCAM1iUyFNSUvwSeSCGDRumL774QuvXr2/4/c+ARA4AQAgNHz5cy5cv19q1a9WqVSvLr08iBwA4QyM/R24YhkaMGKGlS5dq9erVysnJafi9z4JEDgBwBq8kl8nzgzBs2DAtXrxY//M//6Pk5GQdOHBAkpSamqrExEQTgfhj1joAwBFOPX5mZgvG3LlzdezYMfXq1UstW7b0bUuWLLH0d1GRAwAQAkYjvdKVRA4AcIYofdc6iRwA4AxeQ3KZSMbeyEzkjJEDAGBjVOQAAGegtQ4AgJ2ZTOSKzEROax0AABujIgcAOAOtdQAAbMxryFR7nFnrAADAalTkAABnMLwnNzPnRyASOQDAGRgjBwDAxhgjBwAAkYaKHADgDLTWAQCwMUMmE7llkViK1joAADZGRQ4AcAZa6wAA2JjXK8nEs+DeyHyOnNY6AAA2RkUOAHAGWusAANhYlCZyWusAANgYFTkAwBmi9BWtJHIAgCMYhleGiRXMzJwbSiRyAIAzGIa5qpoxcgAAYDUqcgCAMxgmx8gjtCInkQMAnMHrlVwmxrkjdIyc1joAADZGRQ4AcAZa6wAA2Jfh9cow0VqP1MfPaK0DAGBjVOQAAGegtQ4AgI15DckVfYmc1joAADZGRQ4AcAbDkGTmOfLIrMhJ5AAARzC8hgwTrXWDRA4AQBgZXpmryHn8DAAAx5kzZ47atm2rhIQEdevWTZ9++qml1yeRAwAcwfAaprdgLVmyRKNHj9akSZO0efNm5ebmqk+fPjp06JBlv4tEDgBwBsNrfgvSzJkzNXjwYA0aNEgdO3bUvHnzlJSUpFdeecWyn2XrMfJTEw/qVGvqGX8gkpUfj8xxOcAK5RUn/74bYyKZ2VxRp1pJUnl5ud9+t9stt9td7/iamhpt2rRJEyZM8O2LiYlRXl6eNmzY0PBAfsTWifz48eOSpPX6a5gjAUIn7ZJwRwCE3vHjx5WamhqSa8fHxyszM1PrD5jPFc2aNVN2drbfvkmTJmny5Mn1jv3mm2/k8XiUkZHhtz8jI0Pbtm0zHcsptk7kWVlZKisrU3JyslwuV7jDcYTy8nJlZ2errKxMKSkp4Q4HsBR/343PMAwdP35cWVlZIbtHQkKCSktLVVNTY/pahmHUyzenq8Ybk60TeUxMjFq1ahXuMBwpJSWF/9AhavH33bhCVYn/UEJCghISEkJ+nx86//zzFRsbq4MHD/rtP3jwoDIzMy27D5PdAAAIgfj4eHXp0kWrVq3y7fN6vVq1apW6d+9u2X1sXZEDABDJRo8erfz8fHXt2lXXXHONZs2apcrKSg0aNMiye5DIERS3261JkyaFfUwICAX+vmG1O+64Q4cPH9bEiRN14MABde7cWStWrKg3Ac4MlxGpL48FAADnxBg5AAA2RiIHAMDGSOQAANgYiRwAABsjkSNgoV6KDwiXtWvXql+/fsrKypLL5dKyZcvCHRIQMBI5AtIYS/EB4VJZWanc3FzNmTMn3KEAQePxMwSkW7duuvrqq/XCCy9IOvl2ouzsbI0YMULjx48Pc3SAdVwul5YuXaoBAwaEOxQgIFTkOKdTS/Hl5eX59oViKT4AQPBI5Dinsy3Fd+DAgTBFBQCQSOQAANgaiRzn1FhL8QEAgkcixzk11lJ8AIDgsfoZAtIYS/EB4VJRUaGSkhLf59LSUhUVFSk9PV2tW7cOY2TAufH4GQL2wgsv6Omnn/YtxTd79mx169Yt3GEBpq1evVq9e/eutz8/P18LFy5s/ICAIJDIAQCwMcbIAQCwMRI5AAA2RiIHAMDGSOQAANgYiRwAABsjkQMAYGMkcgAAbIxEDgCAjZHIAZPuu+8+DRgwwPe5V69eGjlyZKPHsXr1arlcLh09evSMx7hcLi1btizga06ePFmdO3c2FdeuXbvkcrlUVFRk6joATo9Ejqh03333yeVyyeVyKT4+Xu3atdPUqVNVV1cX8nu/9dZbmjZtWkDHBpJ8AeBsWDQFUeumm27SggULVF1drb/+9a8aNmyYmjRpogkTJtQ7tqamRvHx8ZbcNz093ZLrAEAgqMgRtdxutzIzM9WmTRsNGTJEeXl5evvttyX9ux0+ffp0ZWVlqX379pKksrIy3X777WrevLnS09PVv39/7dq1y3dNj8ej0aNHq3nz5jrvvPP06KOP6sfLFfy4tV5dXa1x48YpOztbbrdb7dq10x//+Eft2rXLt1BHWlqaXC6X7rvvPkknl4ktLCxUTk6OEhMTlZubq7/85S9+9/nrX/+qSy65RImJierdu7dfnIEaN26cLrnkEiUlJemiiy5SQUGBamtr6x334osvKjs7W0lJSbr99tt17Ngxv+9ffvlldejQQQkJCbr00kv1hz/8IehYADQMiRyOkZiYqJqaGt/nVatWqbi4WCtXrtTy5ctVW1urPn36KDk5WevWrdPf//53NWvWTDfddJPvvGeeeUYLFy7UK6+8ovXr1+vIkSNaunTpWe9777336s9//rNmz56trVu36sUXX1SzZs2UnZ2tN998U5JUXFys/fv367nnnpMkFRYWatGiRZo3b57+9a9/adSoUbr77ru1Zs0aSSf/wXHrrbeqX79+Kioq0gMPPKDx48cH/f9JcnKyFi5cqC+//FLPPfec5s+fr2effdbvmJKSEr3xxht65513tGLFCn322WcaOnSo7/vXXntNEydO1PTp07V161bNmDFDBQUFevXVV4OOB0ADGEAUys/PN/r3728YhmF4vV5j5cqVhtvtNsaMGeP7PiMjw6iurvad86c//clo37694fV6ffuqq6uNxMRE4/333zcMwzBatmxpPPXUU77va2trjVatWvnuZRiG0bNnT+Phhx82DMMwiouLDUnGypUrTxvnhx9+aEgyvv32W9++qqoqIykpyfjoo4/8jr3//vuNu+66yzAMw5gwYYLRsWNHv+/HjRtX71o/JslYunTpGb9/+umnjS5duvg+T5o0yYiNjTW+/vpr37733nvPiImJMfbv328YhmH85Cc/MRYvXux3nWnTphndu3c3DMMwSktLDUnGZ599dsb7Amg4xsgRtZYvX65mzZqptrZWXq9Xv/rVrzR58mTf9506dfIbF9+yZYtKSkqUnJzsd52qqirt2LFDx44d0/79+/3WYI+Li1PXrl3rtddPKSoqUmxsrHr27Blw3CUlJTpx4oR+9rOf+e2vqanRlVdeKUnaunVrvbXgu3fvHvA9TlmyZIlmz56tHTt2qKKiQnV1dUpJSfE7pnXr1rrwwgv97uP1elVcXKzk5GTt2LFD999/vwYPHuw7pq6uTqmpqUHHAyB4JHJErd69e2vu3LmKj49XVlaW4uL8/9ybNm3q97miokJdunTRa6+9Vu9aF1xwQYNiSExMDPqciooKSdK7777rl0Clk+P+VtmwYYMGDhyoKVOmqE+fPkpNTdXrr7+uZ555JuhY58+fX+8fFrGxsZbFCuDMSOSIWk2bNlW7du0CPv6qq67SkiVL1KJFi3pV6SktW7bUJ598ohtuuEHSycpz06ZNuuqqq057fKdOneT1erVmzRrl5eXV+/5UR8Dj8fj2dezYUW63W3v27DljJd+hQwffxL1TPv7443P/yB/46KOP1KZNGz322GO+fbt376533J49e7Rv3z5lZWX57hMTE6P27dsrIyNDWVlZ2rlzpwYOHBjU/QFYg8luwPcGDhyo888/X/3799e6detUWlqq1atX66GHHtLXX38tSXr44Yf1xBNPaNmyZdq2bZuGDh161mfA27Ztq/z8fP3617/WsmXLfNd84403JElt2rSRy+XS8uXLdfjwYVVUVCg5OVljxozRqFGj9Oqrr2rHjh3avHmznn/+ed8EsgcffFDbt2/X2LFjVVxcrMWLF2vhwoVB/d6LL75Ye/bs0euvv64dO3Zo9uzZp524l5CQoPz8fG3ZskXr1q3TQw89pNtvv12ZmZmSpClTpqiwsFCzZ8/WV199pc8//1wLFizQzJkzg4oHQMOQyIHvJSUlae3atWrdurVuvfVWdejQQffff7+qqqp8Ffojjzyie+65R/n5+erevbuSk5P1y1/+8qzXnTt3rm677TYNHTpUl156qQYPHqzKykpJ0oUXXqgpU6Zo/PjxysjI0PDhwyVJ06ZNU0FBgQoLC9WhQwfddNNNevfdd5WTkyPp5Lj1m2++qWXLlik3N1fz5s3TjBkzgvq9t9xyi0aNGqXhw4erc+fO+uijj1RQUFDvuHbt2unWW2/Vz3/+c91444264oor/B4ve+CBB/Tyyy9rwYIF6tSpk3r27KmFCxf6YgUQWi7jTLN0AABAxKMiBwDAxkjkAADYGIkcAAAbI5EDAGBjJHIAAGyMRA4AgI2RyAEAsDESOQAANkYiBwDAxkjkAADYGIkcAAAb+/9lNo0U5CRD6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_final, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.82      0.90        11\\n           1       0.88      1.00      0.94        15\\n\\n    accuracy                           0.92        26\\n   macro avg       0.94      0.91      0.92        26\\nweighted avg       0.93      0.92      0.92        26\\n'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.text(0.01, 0.6, str(f'log_reg Test'), {\n",
    "        'fontsize': 10}, fontproperties='monospace')\n",
    "plt.text(0.01, 0.7, str(classification_report(y, preds)), {\n",
    "    'fontsize': 10}, fontproperties='monospace')  # approach improved by OP -> monospace!\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostics import model_predictions   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_predictions(model, X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  2],\n",
       "       [ 0, 15]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>version</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric version score\n",
       "0     f1       0     0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nciw</td>\n",
       "      <td>100</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsid</td>\n",
       "      <td>68</td>\n",
       "      <td>282</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pwls</td>\n",
       "      <td>71</td>\n",
       "      <td>949</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bqlx</td>\n",
       "      <td>686</td>\n",
       "      <td>3782</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmei</td>\n",
       "      <td>45</td>\n",
       "      <td>655</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corporation  lastmonth_activity  lastyear_activity  number_of_employees  \\\n",
       "0        nciw                 100               1359                    1   \n",
       "1        lsid                  68                282                   14   \n",
       "2        pwls                  71                949                   40   \n",
       "3        bqlx                 686               3782                  103   \n",
       "4        zmei                  45                655                    7   \n",
       "\n",
       "   exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1125/561826174.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data.mean(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      365.00\n",
       "1       91.00\n",
       "2      265.25\n",
       "3     1142.75\n",
       "4      176.75\n",
       "5       10.00\n",
       "6      292.25\n",
       "7      269.25\n",
       "8       14.00\n",
       "9       20.50\n",
       "10     264.25\n",
       "11     178.50\n",
       "12     887.75\n",
       "13      46.25\n",
       "14     147.25\n",
       "15     239.25\n",
       "16     486.00\n",
       "17     278.75\n",
       "18     544.75\n",
       "19    1027.00\n",
       "20    2771.75\n",
       "21      40.25\n",
       "22     730.50\n",
       "23     120.75\n",
       "24     241.50\n",
       "25     373.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdated =  subprocess.run(\"pip list --outdated --format columns\",\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        check=True,\n",
    "        text=True).stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Package                Version   Latest    Type\\n---------------------- --------- --------- -----\\naioitertools           0.10.0    0.11.0    wheel\\naltair                 4.1.0     4.2.0     wheel\\nantlr4-python3-runtime 4.9.3     4.11.1    wheel\\nbilliard               3.6.4.0   4.0.2     wheel\\nboto3                  1.24.59   1.24.76   wheel\\nbotocore               1.27.59   1.27.76   wheel\\ncertifi                2022.6.15 2022.9.14 wheel\\ncryptography           37.0.4    38.0.1    wheel\\ndulwich                0.20.45   0.20.46   wheel\\ndvc                    2.24.0    2.27.2    wheel\\ndvc-data               0.4.0     0.10.1    wheel\\ndvc-http               2.19.1    2.27.2    wheel\\ndvc-objects            0.2.0     0.4.1     wheel\\ndvc-render             0.0.9     0.0.11    wheel\\ndvc-s3                 2.19.0    2.20.1    wheel\\nfastapi                0.81.0    0.85.0    wheel\\nfastjsonschema         2.16.1    2.16.2    wheel\\nFlask                  0.12.2    2.2.2     wheel\\nfonttools              4.37.1    4.37.3    wheel\\ngrandalf               0.6       0.7       wheel\\nidna                   3.3       3.4       wheel\\nimportlib-metadata     4.11.4    4.12.0    wheel\\nipykernel              6.15.2    6.15.3    wheel\\nipython                8.4.0     8.5.0     wheel\\njoblib                 1.1.0     1.2.0     wheel\\njson5                  0.9.5     0.9.10    wheel\\njsonschema             4.15.0    4.16.0    wheel\\njupyterlab             3.4.5     3.4.7     wheel\\nmarkdown2              2.3.5     2.4.3     wheel\\nmatplotlib             3.5.3     3.6.0     wheel\\nnbclient               0.6.7     0.6.8     wheel\\nnbformat               5.4.0     5.5.0     wheel\\nnumpy                  1.23.2    1.23.3    wheel\\npandas                 1.4.4     1.5.0     wheel\\npathspec               0.9.0     0.10.1    wheel\\nprompt-toolkit         3.0.30    3.0.31    wheel\\npsutil                 5.9.1     5.9.2     wheel\\npydantic               1.10.1    1.10.2    wheel\\nPyPDF2                 2.10.5    2.10.9    wheel\\npyzmq                  23.2.1    24.0.0    wheel\\nscmrepo                0.0.25    0.1.1     wheel\\nseaborn                0.11.2    0.12.0    wheel\\nSQLAlchemy             1.4.40    1.4.41    wheel\\nstarlette              0.19.1    0.20.4    wheel\\ntabulate               0.8.2     0.8.10    wheel\\ntraitlets              5.3.0     5.4.0     wheel\\nurllib3                1.26.11   1.26.12   wheel\\nwebsocket-client       1.4.0     1.4.1     wheel\\nxhtml2pdf              0.2.2     0.2.8     wheel\\n'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"practicedata/dataset1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset1.csv'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename.replace(\"practicedata/\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Package                Version   Latest    T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  b'Package                Version   Latest    T..."
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([outdated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdated.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import STDOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'stdout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 82\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#Y162sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m outdated\u001b[39m.\u001b[39;49mstdout\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'stdout'"
     ]
    }
   ],
   "source": [
    "outdated.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+02, 1.3590e+03, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.8000e+01, 2.8200e+02, 1.4000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.1000e+01, 9.4900e+02, 4.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.8600e+02, 3.7820e+03, 1.0300e+02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [4.5000e+01, 6.5500e+02, 7.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 1.8000e+01, 2.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.8900e+02, 9.6100e+02, 1.8000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.6000e+01, 1.0280e+03, 3.3000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.0000e+00, 4.5000e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 6.7000e+01, 1.4000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [4.8000e+01, 9.8600e+02, 2.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [5.2000e+01, 6.5000e+02, 1.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0900e+03, 2.4520e+03, 9.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.0000e+00, 8.8000e+01, 9.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.9000e+01, 3.9000e+02, 9.9000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.5000e+01, 8.0000e+02, 8.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [2.5500e+02, 1.6870e+03, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.8000e+01, 1.0240e+03, 1.2000e+01, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.4000e+01, 2.1450e+03, 2.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.8200e+02, 3.8910e+03, 3.5000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0100e+02, 1.0983e+04, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 1.1800e+02, 4.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.2900e+02, 1.9920e+03, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.9000e+01, 4.5500e+02, 8.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "       [9.4000e+01, 8.6800e+02, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [8.1000e+01, 1.4010e+03, 1.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = os.path.join(config['test_data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess_data(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+02, 1.3590e+03, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.8000e+01, 2.8200e+02, 1.4000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.1000e+01, 9.4900e+02, 4.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.8600e+02, 3.7820e+03, 1.0300e+02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [4.5000e+01, 6.5500e+02, 7.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 1.8000e+01, 2.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.8900e+02, 9.6100e+02, 1.8000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.6000e+01, 1.0280e+03, 3.3000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.0000e+00, 4.5000e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 6.7000e+01, 1.4000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [4.8000e+01, 9.8600e+02, 2.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [5.2000e+01, 6.5000e+02, 1.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0900e+03, 2.4520e+03, 9.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [6.0000e+00, 8.8000e+01, 9.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.9000e+01, 3.9000e+02, 9.9000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.5000e+01, 8.0000e+02, 8.1000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [2.5500e+02, 1.6870e+03, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.8000e+01, 1.0240e+03, 1.2000e+01, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.4000e+01, 2.1450e+03, 2.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.8200e+02, 3.8910e+03, 3.5000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0100e+02, 1.0983e+04, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 1.1800e+02, 4.2000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [9.2900e+02, 1.9920e+03, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.9000e+01, 4.5500e+02, 8.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "       [9.4000e+01, 8.6800e+02, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [8.1000e+01, 1.4010e+03, 1.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "f1score = score_model(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "f1 = score_model(X_final, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = glob(f\"{os.path.join(os.getcwd(), test_data_path)}/*.csv\")\n",
    "data = pd.read_csv(datafiles[0])\n",
    "y_temp = data[\"exited\"]\n",
    "X_temp = data.drop(columns=[\"exited\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>werf</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdfv</td>\n",
       "      <td>14</td>\n",
       "      <td>2145</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edcv</td>\n",
       "      <td>34</td>\n",
       "      <td>333</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uhgr</td>\n",
       "      <td>101</td>\n",
       "      <td>12346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okjh</td>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corporation  lastmonth_activity  lastyear_activity  number_of_employees\n",
       "0        werf                 234                  3                   10\n",
       "1        sdfv                  14               2145                   99\n",
       "2        edcv                  34                333                 1000\n",
       "3        uhgr                 101              12346                    2\n",
       "4        okjh                   0                675                   25"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>werf</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdfv</td>\n",
       "      <td>14</td>\n",
       "      <td>2145</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edcv</td>\n",
       "      <td>34</td>\n",
       "      <td>333</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uhgr</td>\n",
       "      <td>101</td>\n",
       "      <td>12346</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okjh</td>\n",
       "      <td>0</td>\n",
       "      <td>675</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corporation  lastmonth_activity  lastyear_activity  number_of_employees\n",
       "0        werf                 234                  3                   10\n",
       "1        sdfv                  14               2145                   99\n",
       "2        edcv                  34                333                 1000\n",
       "3        uhgr                 101              12346                    2\n",
       "4        okjh                   0                675                   25"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical = X_temp[\"corporation\"].values\n",
    "X_continuous = X_temp.drop([\"corporation\"], axis=1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "X_categorical = encoder.fit_transform(X_categorical.reshape(-1,1))\n",
    "# df_newdata = X_categorical.reindex(labels=df_olddata.columns,axis=1)\n",
    "# X_categorical = encoder.transform(X_categorical)\n",
    "# X_categorical = encoder.fit(X_categorical)\n",
    "\n",
    "\n",
    "X_test1 = np.concatenate([X_continuous, X_categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = X_temp[\"corporation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>werf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sdfv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edcv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uhgr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okjh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corporation\n",
       "0        werf\n",
       "1        sdfv\n",
       "2        edcv\n",
       "3        uhgr\n",
       "4        okjh"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_abc = encoder.fit(abc.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cde = X_abc.transform(abc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_check = pd.DataFrame(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2= pd.DataFrame(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = X_test2.reindex(labels=x_check.columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>12346.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2    3    4    5    6    7\n",
       "0  234.0      3.0    10.0  0.0  0.0  0.0  0.0  1.0\n",
       "1   14.0   2145.0    99.0  0.0  0.0  1.0  0.0  0.0\n",
       "2   34.0    333.0  1000.0  1.0  0.0  0.0  0.0  0.0\n",
       "3  101.0  12346.0     2.0  0.0  0.0  0.0  1.0  0.0\n",
       "4    0.0    675.0    25.0  0.0  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.0</td>\n",
       "      <td>12346.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1       2    3    4    5    6    7   8   9   ...  19  20  21  \\\n",
       "0  234.0      3.0    10.0  0.0  0.0  0.0  0.0  1.0 NaN NaN  ... NaN NaN NaN   \n",
       "1   14.0   2145.0    99.0  0.0  0.0  1.0  0.0  0.0 NaN NaN  ... NaN NaN NaN   \n",
       "2   34.0    333.0  1000.0  1.0  0.0  0.0  0.0  0.0 NaN NaN  ... NaN NaN NaN   \n",
       "3  101.0  12346.0     2.0  0.0  0.0  0.0  1.0  0.0 NaN NaN  ... NaN NaN NaN   \n",
       "4    0.0    675.0    25.0  0.0  1.0  0.0  0.0  0.0 NaN NaN  ... NaN NaN NaN   \n",
       "\n",
       "   22  23  24  25  26  27  28  \n",
       "0 NaN NaN NaN NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN NaN NaN NaN  \n",
       "4 NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test3.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corporation</th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nciw</td>\n",
       "      <td>100</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lsid</td>\n",
       "      <td>68</td>\n",
       "      <td>282</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pwls</td>\n",
       "      <td>71</td>\n",
       "      <td>949</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bqlx</td>\n",
       "      <td>686</td>\n",
       "      <td>3782</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmei</td>\n",
       "      <td>45</td>\n",
       "      <td>655</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wosl</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xcvb</td>\n",
       "      <td>189</td>\n",
       "      <td>961</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dfgh</td>\n",
       "      <td>16</td>\n",
       "      <td>1028</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ngrd</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xful</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kshe</td>\n",
       "      <td>48</td>\n",
       "      <td>986</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>qqqq</td>\n",
       "      <td>52</td>\n",
       "      <td>650</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>corp</td>\n",
       "      <td>1090</td>\n",
       "      <td>2452</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ekci</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dosk</td>\n",
       "      <td>99</td>\n",
       "      <td>390</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>endi</td>\n",
       "      <td>75</td>\n",
       "      <td>800</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gudj</td>\n",
       "      <td>255</td>\n",
       "      <td>1687</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abcd</td>\n",
       "      <td>78</td>\n",
       "      <td>1024</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>asdf</td>\n",
       "      <td>14</td>\n",
       "      <td>2145</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xyzz</td>\n",
       "      <td>182</td>\n",
       "      <td>3891</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acme</td>\n",
       "      <td>101</td>\n",
       "      <td>10983</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>qwer</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tyui</td>\n",
       "      <td>929</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>zxcv</td>\n",
       "      <td>19</td>\n",
       "      <td>455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hjkl</td>\n",
       "      <td>94</td>\n",
       "      <td>868</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lmno</td>\n",
       "      <td>81</td>\n",
       "      <td>1401</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corporation  lastmonth_activity  lastyear_activity  number_of_employees\n",
       "0         nciw                 100               1359                    1\n",
       "1         lsid                  68                282                   14\n",
       "2         pwls                  71                949                   40\n",
       "3         bqlx                 686               3782                  103\n",
       "4         zmei                  45                655                    7\n",
       "5         wosl                   0                 18                   21\n",
       "6         xcvb                 189                961                   18\n",
       "7         dfgh                  16               1028                   33\n",
       "8         ngrd                   9                 45                    1\n",
       "9         xful                   0                 67                   14\n",
       "10        kshe                  48                986                   22\n",
       "11        qqqq                  52                650                   11\n",
       "12        corp                1090               2452                    9\n",
       "13        ekci                   6                 88                   90\n",
       "14        dosk                  99                390                   99\n",
       "15        endi                  75                800                   81\n",
       "16        gudj                 255               1687                    2\n",
       "17        abcd                  78               1024                   12\n",
       "18        asdf                  14               2145                   20\n",
       "19        xyzz                 182               3891                   35\n",
       "20        acme                 101              10983                    2\n",
       "21        qwer                   0                118                   42\n",
       "22        tyui                 929               1992                    1\n",
       "23        zxcv                  19                455                    8\n",
       "24        hjkl                  94                868                    3\n",
       "25        lmno                  81               1401                   10"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1 = ohe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3400e+02, 3.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "       [1.4000e+01, 2.1450e+03, 9.9000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [3.4000e+01, 3.3300e+02, 1.0000e+03, 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0100e+02, 1.2346e+04, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 6.7500e+02, 2.5000e+01, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"abcdefghi\", \"uvwxyz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1defghi\n",
      "uvwxyz\n"
     ]
    }
   ],
   "source": [
    "q = []\n",
    "for  t, i in enumerate(test):\n",
    "    pq = i.replace(\"abc\", \"1\")\n",
    "    print(pq)\n",
    "# print(pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uvwxyz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = df.select_dtypes([np.number]).agg([\"mean\", \"median\", \"std\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastmonth_activity</th>\n",
       "      <th>lastyear_activity</th>\n",
       "      <th>number_of_employees</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.235294</td>\n",
       "      <td>952.882353</td>\n",
       "      <td>33.294118</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>289.157511</td>\n",
       "      <td>973.517134</td>\n",
       "      <td>36.067237</td>\n",
       "      <td>0.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lastmonth_activity  lastyear_activity  number_of_employees     exited\n",
       "mean            165.235294         952.882353            33.294118   0.588235\n",
       "median           68.000000         800.000000            18.000000   1.000000\n",
       "std             289.157511         973.517134            36.067237   0.507300\n",
       "count            17.000000          17.000000            17.000000  17.000000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df.describe()\n",
    "mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lastmonth_activity', 'lastyear_activity', 'number_of_employees', 'exited']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostics import check_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = dataframe_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(summary)[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isna().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[165.23529411764707,\n",
       "  952.8823529411765,\n",
       "  33.294117647058826,\n",
       "  0.5882352941176471],\n",
       " [68.0, 800.0, 18.0, 1.0],\n",
       " [289.1575110151396, 973.5171340526666, 36.06723704742705, 0.5072996561958923],\n",
       " [17.0, 17.0, 17.0, 17.0]]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/seun-ajayi/Project_4/check.ipynb Cell 144\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/seun-ajayi/Project_4/check.ipynb#Y264sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m X_final\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_final' is not defined"
     ]
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-09-23-01-21-57'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tourmaline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bbd94e82390f0f30163e7c21020f9971750a48a428abb8797975cb394d01ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
